

\chapter{LITERATURE SURVEY} \label{chapter1}

\section{introduction:} 

According to the World Federation of Deaf (WFD) \cite{wfd} there are 70 million deaf people in the world, whereas the world population in 2012 exceeded 7 billion, this number has got the power to make research in the field of machine vision  over  the  past  decade become rich with new scientific approaches.
A  more  recent   technology  for gesture   recognition  is to  incorporate   the  information   of object   distances,   or depths,   normally   captured   by a 3D camera,   or a set  of cameras  that  produce 3D images and that it is Technology that will be used in this project. It is also a contact-less  user interface,   in contrast   to glove based   devices  or handhold  remote  sensor.
\newline
With the kinect depth Sensor stream data, it is now possible to recognize and  translate sign language into speech and/or text in order to facilitate communication between normal hearing and hearing impaired people. This is usually called Sign Language Recognition (SLR) which  aim  to automatically understand the meaning of a sequence of signs from sign language without involvement of human interpreter \cite{27}. This chapter covers key aspects of SLR Literature.

\section{ Sign  Language Recognition}  

the SLR system can be divided into 4 important  steps, data acquisition and feature extraction and finally feature combination and sign recognition, following below, we will cover two important approaches of the first step ( data acquisition ) which are  :

\textbf{Device based }:
in  1991 Tomoichi Takahashi   developed a system for real time SLR  using Device based approach, this system required the user to wear gloves connected to the omputer for transmission of hand signal. Experiments showed that 34 of 46 gestures of the japanese Kana manual alphabet were recognized correctly \cite{29}
.
A wireless glove that was designed by Ryan Petters  \cite{31}in 2002, sensed hand movements that are involved in sign language and then transmitted them wirelessly to portable device, that displayed translated signs as lines of text.

\textbf{vision based }:
This approach  \cite{32} here  feature extraction was done using color camera for recognition of ASL. Two experiments were run: the first required from the signer to wear colored gloves,while the second used hand’s skin color for feature extraction\cite{32}. The extracted features were used as input for HMM algorithm that was used during sign recognition phase. The first experiment attained 99\% word accuracy while the second 92\%.
 
Two experiments were carried out also in \cite{33} on a SLR system that combined computer vision and HMM for recognition of sentence level continuous ASL. Both systems were tested with 40 words from ASL, where in the first system a single camera was mounted on desk to track user’s hands and achieved 92\% word accuracy, while in the second system the user had to wear a cap worm in which camera was mounted and the achieved accuracy was 97\%  \cite{33}.



The presentation of all the work related to SLR is not the intention of this section and more can be found on  \cite{27},\cite{36} and \cite{39}. 

The following section presents work that employed Kinect device for building SLR systems in which we are going to discover The main ideas behind our project 

\section{Gesture Recognition Using Kinect :}

in \cite{35} Zhou Ren et al presents a gesture recognition System using Kinect sensor accompanied with a novel distance metric called Finger-Earth Mover’s Distance (FEMD) to measure the hand shape dissimilarities, which achieves better performance than Shape Context, in terms of accuracy (a 93.9\% mean accuracy) and efficiency (0.5004s). 

A more recent approach followed by Daniel in \cite{47} uses Kinect skeletal tracking for features extraction. Other features were derived from skeletal tracking and finally 8-features were used for unique description of each sign. Sign recognition employs the nearest neighbor algorithm that tries to find the closest matching of performed sign within a group of stored sings  For a dictionary of 14 homemade signs the system achieves an accuracy of 95\% \cite{47}. 

in \cite{dardas} this paper presents an effective way of exploring depth information for hand gesture recognition. using  SIFT keypoint descriptor to extract local keypoint features over depth images,  which is an attempt for the first time in gesture recognition research. The recognition technique is inherently robust against scaling, rotation, and illumination conditions.  The features were  quantified  and clustered, and finally fed to  An SVM to be trained.\\


\textbf{ Insipired HGR system  of this project : }


\textbf{with \cite{dardas} and \cite{47} } we got inspired for our most work dedicated for this project, we take advantage of  depth and Skeletal tracking  data generated by Kinect to detect the hand and track it  in a range of [80 cm until 3 meters] long.
After detection of hand, we used SURF and SIFT descriptors for features detection and extraction then we  cluster these vectors via a bag-of-features (BOW) model, these features are then fed to an SVM with two different kernels linear and RBF kernel.

on the other hand unlike most systems like \cite{33} that use HMM,  we proposed and tested a method for static hand gesture recognition using  Fourier shape  descriptor which proved to be a very efficient way for feature extraction, it provided a set of invariant features for each image,  and provided a small number of features compared to local image descriptor, we found NN classifier to give faster and better results for Fourier descriptor.
\newpage
\section{Conclusion}

We can summarize The process used in SLR literature as the following:

Getting data from a sign performing can either be device based or/and vision approach, then features
involved in sign making must be extracted and finally combination of features must be analyzed 

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{img/SLR.PNG}
\caption{  Process of SLR }
\label{fig:SLR}
\end{figure}

In the next Chapter we will cover image descriptors as the second step of our HGR system,we will go through some of the important feature of these descriptor and how it can benefits our purposes in making Robust and accurate HGR System. 